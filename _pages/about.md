---
permalink: /
title: "About Me "
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Yuanjie Lu is a PhD student in Computer Science at George Mason University, working in the [**Robotixx Lab**](https://robotixx.cs.gmu.edu/) under the supervision of [**Prof. Xuesu Xiao**](https://cs.gmu.edu/~xiao/). He is also affiliated with [**The Center for Human-AI Innovation in Society**](https://chais.gmu.edu/). His research centers on autonomous navigation and decision-making for robots, emphasizing motion planning, learning-based control, and the integration of foundation models. His work aims to bridge low-level control and high-level reasoning through adaptive frameworks that unify perception, planning, and control.

## ü§ù Collaborations

His research journey has progressed from **machine learning and deep learning for autonomous systems** through **motion planning algorithms in robotics** to **real-world robot navigation** and **foundation model-driven autonomy**.

He first worked with [**Dr. Amarda Shehu**](https://cs.gmu.edu/~ashehu/) and [**Dr. David Lattanzi**](https://volgenau.gmu.edu/profiles/dlattanz) at **George Mason University (GMU)** on **data-driven anomaly forecasting for autonomous systems**. He then collaborated with the **Virginia Department of Transportation (VDOT)** on **graph neural networks for traffic flow forecasting** under non-recurring disruptions such as work zones and lane closures.

Subsequently, he joined [**Dr. Erion Plaku**](https://erionplaku.github.io/)'s lab, where he studied **motion planning algorithms** that integrate learning with classical planners, building on foundations in dynamic programming and search-based methods. He later collaborated with [**Prof. Nick Hawes**](https://www.robots.ox.ac.uk/~nickh/) at **Oxford University** on **robot dynamics and adaptive control**, [**Dr. Tinoosh Mohsenin**](https://eehpc.ece.jhu.edu/tinoosh-mohsenin/) at **Johns Hopkins University** on **quadruped navigation**, and [**Dr. Xiaomin Lin**](https://xiaominlin.github.io/) on **LLM/VLM-driven robot navigation**.

Together, these collaborations bridge **data-driven modeling**, **motion planning**, **learning-based navigation**, and **foundation model integration**, forming a cohesive trajectory toward intelligent and reliable robotic autonomy.


## Research Interests
  * ***Deep Learning & Reinforcement Learning for Autonomous Robot Navigation***
  * ***AI-driven Decision-Making for Robot Motion Planning and Control*** 
  * ***LLMs and VLMs for Low-Level Decision-Making in Robot Navigation***

## Recent Projects
### Adaptive Dynamics Planning (ADP) for Robot Navigation
*Combining Motion Planning with TD3-Based Reinforcement Learning for Real-Time Dynamics Adaptation in Mapless, Constrained Environments*

<img src="/images/ICRA2026_1.gif" width="330"> <img src="/images/ICRA2026_0.gif" width="330">

---

### Autonomous Navigation for Legged Robots (Summer 2025 @ JHU)
*Autonomous Navigation for Legged Robots in Complex Environments*

  <img src="/images/jhu1.gif" width="330">  <img src="/images/jhu4.gif" width="330">
  <img src="/images/jhu3.gif" width="330">  <img src="/images/jhu5.gif" width="330">

### Adaptive Locomotion for Quadruped Robots in Unstructured Terrain (Summer 2024 @ Unitree)
*Reinforcement Learning-Based Balance and Mobility Control for Legged Robots Traversing Rocky Terrain and Stairs*

  <img src="/images/IROS2025.gif" width="330"> <img src="/images/IROS20251.gif" width="330">
  

## News
* **[Oct 2025]** Preparing three papers on LLM/VLM-based navigation in collaboration with the University of South Florida and the University of Maryland
* **[Sep 2025]** Paper "Autonomous Ground Navigation in Highly Constrained Spaces" published in IEEE ICRA 2025 (BARN Challenge Competition Track)
* **[Sep 2025]** Our paper "Adaptive Dynamics Planning for Robot Navigation" submitted to IEEE ICRA 2026
* **[Jul 2025]** Our work is supported by Google DeepMind, Clearpath Robotics, Raytheon Technologies, Tangenta, Mason Innovation Exchange (MIX), and Walmart
* **[May 2025]** Two papers accepted to IEEE IROS 2025: "Decremental Dynamics Planning for Robot Navigation" and "Reward Training Wheels: Adaptive Auxiliary Rewards for Robotics Reinforcement Learning"
* **[May 2025]** Started Research Engineer position at Johns Hopkins University
* **[Mar 2025]** Our work is supported by National Science Foundation (NSF), Army Research Office (ARO) and Air Force Research Laboratory (AFRL)
* **[Jan 2025]** Paper "Multi-goal Motion Memory for Robot Navigation" accepted to IEEE ICRA 2025
* **[Nov 2024]** Won 2nd place in the 2025 BARN Challenge
